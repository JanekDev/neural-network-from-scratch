{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing simple neural network from scratch\n",
    "In this notebook I implemented a simple neural network without using advanced ML libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from common import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward_pass(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backpropagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class FullyConnectedLayer(Layer):\n",
    "    def __init__(self, input_size, output_size, init_method=\"random\"):\n",
    "        if init_method == \"random\":\n",
    "            self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "            self.bias = np.random.rand(1, output_size) - 0.5\n",
    "        elif init_method == \"zeros\":\n",
    "            self.weights = np.zeros((input_size, output_size))\n",
    "            self.bias = np.zeros((1, output_size))\n",
    "        elif init_method == \"xavier\":\n",
    "            self.weights = np.random.randn(input_size, output_size) * np.sqrt(\n",
    "                2 / (input_size + output_size)\n",
    "            )\n",
    "            self.bias = np.random.randn(1, output_size) * np.sqrt(\n",
    "                2 / (input_size + output_size)\n",
    "            )\n",
    "        elif init_method == \"he\":\n",
    "            self.weights = np.random.randn(input_size, output_size) * np.sqrt(\n",
    "                2 / input_size\n",
    "            )\n",
    "            self.bias = np.random.randn(1, output_size) * np.sqrt(2 / input_size)\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backpropagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error\n",
    "\n",
    "\n",
    "class ActivationComponent(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backpropagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "        self.convergence = []\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def set_loss(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "        for i in range(samples):\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_pass(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate, printc=False):\n",
    "        samples = len(x_train)\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_pass(output)\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backpropagation(error, learning_rate)\n",
    "\n",
    "            err /= samples\n",
    "            self.convergence.append(err)\n",
    "            if printc:\n",
    "                print(f\"Epoch: {i}, Error: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist data\n",
    "x_train, y_train = load_mnist(\"mnist\", kind=\"train\")\n",
    "x_test, y_test = load_mnist(\"mnist\", kind=\"t10k\")\n",
    "# convert to one-hot encoding\n",
    "y_train = np.eye(10)[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data representation\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = Network()\n",
    "mnist_net.add(FullyConnectedLayer(784, 128, \"random\"))\n",
    "mnist_net.add(ActivationComponent(tanh, tanh_prime))\n",
    "mnist_net.add(FullyConnectedLayer(128, 64, \"random\"))\n",
    "mnist_net.add(ActivationComponent(tanh, tanh_prime))\n",
    "mnist_net.add(FullyConnectedLayer(64, 10, \"random\"))\n",
    "mnist_net.add(ActivationComponent(softmax, softmax_prime))\n",
    "mnist_net.set_loss(cross_entropy, cross_entropy_prime)\n",
    "mnist_net.fit(x_train, y_train, epochs=20, learning_rate=0.001)\n",
    "# save the model\n",
    "mnist_net.save(\"mnist_net.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 6\n",
      "Accuracy: 0.9073\n"
     ]
    }
   ],
   "source": [
    "# get random image from the test set\n",
    "idx = np.random.randint(len(x_test))\n",
    "img = x_test[idx]\n",
    "plt.imshow(img.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# show the example prediction\n",
    "prediction = np.argmax(mnist_net.predict(img.reshape(1, 784)))\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# get the accuracy\n",
    "y_pred = [np.argmax(mnist_net.predict(i)) for i in x_test]\n",
    "accuracy = np.sum(\n",
    "    [1 if y_pred[i] == y_test[i] else 0 for i in range(len(y_pred))]\n",
    ") / len(y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31dca9b9ee8cbd0c32cc854109fa72488c93dc0b9bf0becddd230d6e94c6411a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
