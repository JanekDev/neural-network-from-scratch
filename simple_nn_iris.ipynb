{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing simple neural network from scratch\n",
    "In this notebook I implemented a simple neural network without using advanced ML libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward_pass(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backpropagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class FullyConnectedLayer(Layer):\n",
    "    def __init__(self, input_size, output_size, init_method='random'):\n",
    "        # TODO: #1 init_method\n",
    "        # weiths and bias are initialized randomly\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    def forward_pass(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backpropagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error\n",
    "\n",
    "class ActivationComponent(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error\n",
    "\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "        self.convergence=[]\n",
    "\n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "        for i in range(samples):\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        samples = len(x_train)\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "                    \n",
    "            err /= samples\n",
    "            self.convergence.append(err)\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization\n",
    "- Iris-setosa : red\n",
    "- Iris-versicolor: green\n",
    "- Iris-virginica: blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get iris\n",
    "iris = pd.read_csv('iris.csv')\n",
    "plot_iris_data(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.add(FullyConnectedLayer(4, 100))\n",
    "net.add(ActivationComponent(tanh, tanh_prime))\n",
    "net.add(FullyConnectedLayer(100, 50))\n",
    "net.add(ActivationComponent(tanh, tanh_prime))\n",
    "net.add(FullyConnectedLayer(50, 10))\n",
    "net.add(ActivationComponent(tanh, tanh_prime))\n",
    "net.add(FullyConnectedLayer(10, 3))\n",
    "\n",
    "# convert species to one-hot encoding\n",
    "iris['Species'] = iris['Species'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
    "\n",
    "# split data into training and test set (80%/20%)\n",
    "iris_train = iris.sample(frac=0.8)\n",
    "iris_test = iris.drop(iris_train.index)\n",
    "# convert to numpy arrays\n",
    "iris_train = iris_train.to_numpy()\n",
    "iris_test = iris_test.to_numpy()\n",
    "# normalize data (0-1)\n",
    "for i in range(4):\n",
    "    iris_train[:, i] = (iris_train[:, i] - iris_train[:, i].min()) / (iris_train[:, i].max() - iris_train[:, i].min())\n",
    "    iris_test[:, i] = (iris_test[:, i] - iris_test[:, i].min()) / (iris_test[:, i].max() - iris_test[:, i].min())\n",
    "iris_train_x = iris_train[:, :4]\n",
    "iris_train_y = np_utils.to_categorical(iris_train[:, 4])\n",
    "iris_test_x = iris_test[:, :4]\n",
    "iris_test_y =  iris_test[:, 4]\n",
    "iris_train_x =iris_train_x.reshape(iris_train_x.shape[0], 1, 4)\n",
    "\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(iris_train_x,iris_train_y, epochs=10, learning_rate=0.1)\n",
    "\n",
    "#make accuracy prediction\n",
    "pred = net.predict(iris_test_x)\n",
    "print(iris_test_y)\n",
    "print(pred)\n",
    "for prediction in pred:\n",
    "    print(np.argmax(prediction))\n",
    "# calculate accuracy\n",
    "correct = 0\n",
    "for i in range(len(iris_test_y)):\n",
    "    if np.argmax(pred[i]) == iris_test_y[i]:\n",
    "        correct += 1\n",
    "print('accuracy: %f' % (correct / len(iris_test_y)))\n",
    "# plot convergence\n",
    "plt.plot(range(len(net.convergence)), net.convergence)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79be5273dd2a4b10d2c1f0e02d55929a76c8c0f215cdd8360fa7ff2fae9a0653"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
